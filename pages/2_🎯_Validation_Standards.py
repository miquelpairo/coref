"""
Standard Validation Tool (OPTIMIZED)
=====================================
Herramienta dedicada para validaci√≥n de est√°ndares √≥pticos NIR.
Verifica alineamiento espectral post-mantenimiento.

OPTIMIZADO: Usa funciones compartidas de core.standards_analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List
import sys
from pathlib import Path
from datetime import datetime

# A√±adir directorio ra√≠z al path
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

from core.file_handlers import load_tsv_file, get_spectral_columns
from auth import check_password
from buchi_streamlit_theme import apply_buchi_styles
from app_config import DEFAULT_VALIDATION_THRESHOLDS, CRITICAL_REGIONS, OFFSET_LIMITS


# ===== IMPORTAR FUNCIONES COMPARTIDAS =====
from core.standards_analysis import (
    validate_standard,
    detect_spectral_shift,
    find_common_ids,
    analyze_critical_regions,
    create_validation_plot,
    create_validation_overlay_plot,
    create_global_statistics_table
)

apply_buchi_styles()



if not check_password():
    st.stop()


# ============================================================================
# INTERFAZ PRINCIPAL
# ============================================================================

def main():
    st.title("üéØ Standard Validation Tool")
    st.markdown("**Validaci√≥n autom√°tica de est√°ndares √≥pticos post-mantenimiento**")
    
    # Info inicial
    st.info("""
    Esta herramienta valida que el alineamiento espectral del equipo se mantiene 
    correcto despu√©s de realizar mantenimiento (ej: cambio de l√°mpara).
    
    **Proceso:**
    1. Carga archivos TSV con mediciones antes y despu√©s del mantenimiento
    2. Selecciona los est√°ndares a validar
    3. Analiza autom√°ticamente la correlaci√≥n y diferencias espectrales
    4. Genera informe detallado con resultados
    """)
    
    st.divider()
    
    # Sidebar con umbrales
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuraci√≥n")
        st.markdown("---")
        
        # Ajuste de umbrales
        with st.expander("üéöÔ∏è Ajustar Umbrales de Validaci√≥n", expanded=True):
            st.caption("Modifica los criterios de aceptaci√≥n seg√∫n tus necesidades")
            
            corr_threshold = st.number_input(
                "Correlaci√≥n m√≠nima:",
                min_value=0.990,
                max_value=1.000,
                value=DEFAULT_VALIDATION_THRESHOLDS['correlation'],
                step=0.001,
                format="%.4f",
                help="Similitud espectral m√≠nima aceptable (valores cercanos a 1.0 = alta similitud)"
            )
            
            max_diff_threshold = st.number_input(
                "Diferencia m√°xima (AU):",
                min_value=0.001,
                max_value=0.100,
                value=DEFAULT_VALIDATION_THRESHOLDS['max_diff'],
                step=0.001,
                format="%.4f",
                help="M√°xima desviaci√≥n puntual permitida en absorbancia"
            )
            
            rms_threshold = st.number_input(
                "RMS m√°ximo:",
                min_value=0.001,
                max_value=0.100,
                value=DEFAULT_VALIDATION_THRESHOLDS['rms'],
                step=0.001,
                format="%.4f",
                help="Error cuadr√°tico medio m√°ximo aceptable"
            )
            
            thresholds = {
                'correlation': corr_threshold,
                'max_diff': max_diff_threshold,
                'rms': rms_threshold
            }
        
        if 'thresholds' not in locals():
            thresholds = DEFAULT_VALIDATION_THRESHOLDS
        
        st.divider()
        
        # Info de regiones cr√≠ticas
        with st.expander("‚ÑπÔ∏è Regiones Espectrales Cr√≠ticas"):
            st.markdown("""
            **Regiones analizadas:**
            - **1100-1200 nm**: Enlaces O-H (hidroxilos)
            - **1400-1500 nm**: Agua / Humedad
            - **1600-1700 nm**: Enlaces C-H (grupos metilo)
            
            Estas regiones son especialmente sensibles a desalineamientos √≥pticos.
            """)
    
    # ==========================================
    # SECCI√ìN: CARGA DE ARCHIVOS TSV
    # ==========================================
    st.markdown("### üìÅ Carga de Archivos de Medici√≥n")

    st.info("""
    Carga dos archivos TSV con mediciones de est√°ndares √≥pticos:

    **Uso t√≠pico:**
    - **Referencia**: Mediciones con baseline antigua (antes de mantenimiento)
    - **Actual**: Mediciones con baseline nueva (despu√©s de mantenimiento)
    """)

    col1, col2 = st.columns(2)

    with col1:
        ref_file = st.file_uploader(
            "Referencia pre-mantenimiento:",
            type=['tsv'],
            key="ref_tsv_validation",
            help="Archivo TSV con mediciones de est√°ndares ANTES del mantenimiento (con baseline antigua)"
        )

    with col2:
        curr_file = st.file_uploader(
            "Medici√≥n post-mantenimiento:",
            type=['tsv'],
            key="curr_tsv_validation",
            help="Archivo TSV con mediciones de est√°ndares DESPU√âS del mantenimiento (con baseline nueva)"
        )

    st.divider()
    
    # √Årea principal
    if not ref_file or not curr_file:
        st.info("üëÜ Carga ambos archivos para comenzar")
        
        with st.expander("üìñ Gu√≠a de Uso", expanded=True):
            st.markdown("""
            ### ¬øC√≥mo funciona esta herramienta?
            
            **1. Preparaci√≥n**
            - Realiza mediciones de est√°ndares √≥pticos ANTES del mantenimiento
            - Exporta las mediciones como archivo TSV (Referencia)
            
            **2. Mantenimiento**
            - Realiza el cambio de l√°mpara u otro mantenimiento
            - Instala el nuevo baseline corregido
            
            **3. Verificaci√≥n**
            - Mide los mismos est√°ndares con el nuevo baseline
            - Exporta las mediciones como archivo TSV (Post-mantenimiento)
            
            **4. Validaci√≥n Autom√°tica**
            - Esta herramienta compara ambos conjuntos de mediciones
            - Detecta desviaciones, correlaciones y shifts espectrales
            - Genera un informe detallado
            
            ---
            
            **Umbrales por defecto:**
            - Correlaci√≥n espectral: ‚â• 0.999
            - Diferencia m√°xima: ‚â§ 0.02 AU
            - RMS: ‚â§ 0.015
            
            Estos valores se pueden ajustar en el panel lateral seg√∫n tus requisitos.
            """)
        
        return
    
    # Cargar archivos usando funciones compartidas
    try:
        with st.spinner("‚è≥ Cargando archivos y detectando est√°ndares comunes..."):
            df_ref = load_tsv_file(ref_file)
            df_curr = load_tsv_file(curr_file)
            
            spectral_cols_ref = get_spectral_columns(df_ref)
            spectral_cols_curr = get_spectral_columns(df_curr)
            
            if len(spectral_cols_ref) != len(spectral_cols_curr):
                st.error("‚ùå Los archivos tienen diferente n√∫mero de canales espectrales")
                st.info(f"""
                - Archivo referencia: {len(spectral_cols_ref)} canales
                - Archivo actual: {len(spectral_cols_curr)} canales
                
                Ambos archivos deben tener el mismo n√∫mero de canales espectrales.
                """)
                return
            
            num_channels = len(spectral_cols_ref)
            
            # Encontrar IDs comunes usando funci√≥n compartida
            matches = find_common_ids(df_ref, df_curr)
            
            if len(matches) == 0:
                st.error("‚ùå No se encontraron IDs comunes entre los archivos")
                st.info("üí° Verifica que:")
                st.markdown("""
                - Los campos **ID** y **Note** existen en ambos archivos
                - Los IDs utilizados son consistentes entre mediciones
                - Ambas mediciones incluyen los mismos est√°ndares
                """)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### IDs en Referencia")
                    if 'ID' in df_ref.columns and 'Note' in df_ref.columns:
                        st.dataframe(df_ref[['ID', 'Note']], use_container_width=True)
                    else:
                        st.warning("Columnas ID o Note no encontradas")
                        
                with col2:
                    st.markdown("#### IDs en Actual")
                    if 'ID' in df_curr.columns and 'Note' in df_curr.columns:
                        st.dataframe(df_curr[['ID', 'Note']], use_container_width=True)
                    else:
                        st.warning("Columnas ID o Note no encontradas")
                
                return
            
        st.success(f"‚úÖ {len(matches)} est√°ndar(es) com√∫n(es) detectado(s)")
            
    except Exception as e:
        st.error(f"‚ùå Error al cargar archivos: {str(e)}")
        with st.expander("üîç Ver detalles del error"):
            import traceback
            st.code(traceback.format_exc())
        return
    
    st.divider()
    
    # ==========================================
    # SECCI√ìN 1: SELECCI√ìN DE EST√ÅNDARES
    # ==========================================
    st.markdown("### 1Ô∏è‚É£ Selecci√≥n de Est√°ndares a Validar")
    
    # Inicializar estado de selecci√≥n
    common_ids = matches['ID'].tolist()

    if 'standards_selected_ids' not in st.session_state:
        st.session_state.standards_selected_ids = common_ids.copy()

    if 'standards_pending_selection' not in st.session_state:
        st.session_state.standards_pending_selection = common_ids.copy()

    # Crear DataFrame para mostrar
    df_samples = pd.DataFrame({
        'ID': common_ids,
        'Note (Ref)': matches['ref_note'].tolist(),
        'Note (Actual)': matches['curr_note'].tolist(),
        'Usar para validaci√≥n': [
            id_ in st.session_state.standards_pending_selection 
            for id_ in common_ids
        ]
    })

    st.info("""
    Selecciona los est√°ndares que deseas incluir en la validaci√≥n. 
    Por defecto, todos los est√°ndares comunes est√°n seleccionados.
    """)

    # Usar formulario
    with st.form("form_select_standards_validation", clear_on_submit=False):
        edited = st.data_editor(
            df_samples,
            use_container_width=True,
            hide_index=True,
            disabled=['ID', 'Note (Ref)', 'Note (Actual)'],
            column_config={
                "Usar para validaci√≥n": st.column_config.CheckboxColumn(
                    "‚úì Incluir",
                    help="Marcar para incluir en la validaci√≥n",
                    default=True,
                )
            },
            key="editor_select_standards_validation"
        )
        
        # Botones dentro del formulario
        col_a, col_b, col_c, col_d = st.columns(4)
        btn_all = col_a.form_submit_button("‚úÖ Todos", use_container_width=True)
        btn_none = col_b.form_submit_button("‚ùå Ninguno", use_container_width=True)
        btn_invert = col_c.form_submit_button("üîÑ Invertir", use_container_width=True)
        btn_confirm = col_d.form_submit_button("üöÄ Confirmar Selecci√≥n", type="primary", use_container_width=True)

    # Manejar acciones de botones
    if btn_all:
        st.session_state.standards_pending_selection = common_ids.copy()
        st.rerun()

    if btn_none:
        st.session_state.standards_pending_selection = []
        st.rerun()

    if btn_invert:
        inverted = [id_ for id_ in common_ids if id_ not in st.session_state.standards_pending_selection]
        st.session_state.standards_pending_selection = inverted
        st.rerun()

    if btn_confirm:
        try:
            pending = edited.loc[edited['Usar para validaci√≥n'], 'ID'].tolist()
            st.session_state.standards_pending_selection = pending
            st.session_state.standards_selected_ids = pending
            st.session_state['validated'] = True
            st.rerun()
        except Exception as e:
            st.error(f"Error al confirmar selecci√≥n: {str(e)}")
    else:
        # Actualizar pending mientras se edita
        if isinstance(edited, pd.DataFrame):
            try:
                pending = edited.loc[edited['Usar para validaci√≥n'], 'ID'].tolist()
                st.session_state.standards_pending_selection = pending
            except Exception:
                pass

    # Mostrar contador
    st.caption(
        f"Pendientes: {len(st.session_state.standards_pending_selection)} - "
        f"Confirmados: {len(st.session_state.get('standards_selected_ids', []))}"
    )

    # Solo proceder si ya se valid√≥
    if 'validated' not in st.session_state or not st.session_state['validated']:
        st.info("üëÜ Ajusta la selecci√≥n y presiona **'Confirmar Selecci√≥n'** para continuar")
        return

    # Recuperar selecci√≥n guardada
    selected_ids = st.session_state.standards_selected_ids
    matches_filtered = matches[matches['ID'].isin(selected_ids)].copy()

    st.divider()

    # Bot√≥n para volver a la selecci√≥n
    if st.button("üîÑ Cambiar Selecci√≥n de Est√°ndares", use_container_width=False):
        st.session_state['validated'] = False
        st.rerun()
    
    # ==========================================
    # SECCI√ìN 2: VALIDACI√ìN AUTOM√ÅTICA
    # ==========================================
    st.markdown("### 2Ô∏è‚É£ Resultados de Validaci√≥n")
    
    all_results = []
    all_validation_data = []
    
    with st.spinner(f"‚è≥ Validando {len(matches_filtered)} est√°ndar(es)..."):
        for idx, row in matches_filtered.iterrows():
            sample_id = row['ID']
            ref_note = row['ref_note']
            curr_note = row['curr_note']
            ref_idx = row['ref_idx']
            curr_idx = row['curr_idx']
            
            # Extraer espectros
            reference = df_ref.loc[ref_idx, spectral_cols_ref].astype(float).values
            current = df_curr.loc[curr_idx, spectral_cols_curr].astype(float).values
            
            # Validar usando funci√≥n compartida
            validation_results = validate_standard(reference, current, thresholds)
            has_shift, shift_magnitude = detect_spectral_shift(reference, current)
            
            # Determinar estado
            if validation_results['pass'] and not has_shift:
                estado = "‚úÖ OK"
                estado_sort = 0
            elif validation_results['pass'] and has_shift:
                estado = "‚ö†Ô∏è Revisar"
                estado_sort = 1
            else:
                estado = "‚ùå Fallo"
                estado_sort = 2
            
            all_results.append({
                'Estado': estado,
                '_sort': estado_sort,
                'ID': sample_id,
                'Note (Ref)': ref_note,
                'Note (Actual)': curr_note,
                'Correlaci√≥n': f"{validation_results['correlation']:.6f}",
                'Max Œî (AU)': f"{validation_results['max_diff']:.6f}",
                'RMS': f"{validation_results['rms']:.6f}",
                'Offset Medio': f"{validation_results['mean_diff']:.6f}",
                'Shift (px)': f"{shift_magnitude:.1f}" if has_shift else "0.0"
            })
            
            # Guardar datos completos
            all_validation_data.append({
                'id': sample_id,
                'ref_note': ref_note,
                'curr_note': curr_note,
                'reference': reference,
                'current': current,
                'diff': validation_results['diff'],
                'validation_results': validation_results,
                'has_shift': has_shift,
                'shift_magnitude': shift_magnitude
            })
    
    # Crear DataFrame de resultados
    results_df = pd.DataFrame(all_results)
    results_df = results_df.sort_values('_sort').drop('_sort', axis=1)
    
    # Resumen general
    n_ok = sum(1 for r in all_results if r['Estado'] == "‚úÖ OK")
    n_warn = sum(1 for r in all_results if r['Estado'] == "‚ö†Ô∏è Revisar")
    n_fail = sum(1 for r in all_results if r['Estado'] == "‚ùå Fallo")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Est√°ndares", len(matches_filtered))
    with col2:
        st.metric("‚úÖ Validados", n_ok)
    with col3:
        st.metric("‚ö†Ô∏è Revisar", n_warn)
    with col4:
        st.metric("‚ùå Fallidos", n_fail)
    
    st.markdown("---")
    
    # Tabla resumen
    st.markdown("#### üìã Tabla Resumen")
    st.dataframe(results_df, use_container_width=True, hide_index=True)
    
    # Exportar resumen
    csv = results_df.to_csv(index=False)
    st.download_button(
        label="üì• Descargar Resumen (CSV)",
        data=csv,
        file_name=f"validation_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True
    )
    
    st.divider()
    
    # ==========================================
    # SECCI√ìN 3: AN√ÅLISIS GLOBAL
    # ==========================================
    st.markdown("### 3Ô∏è‚É£ An√°lisis Global")
    
    # Expandable para gr√°fico overlay usando funci√≥n compartida
    with st.expander("üìä Vista Global de Todos los Est√°ndares", expanded=False):
        st.info("""
        Comparaci√≥n simult√°nea de todos los espectros validados. 
        Las l√≠neas s√≥lidas representan las mediciones de referencia (pre-mantenimiento) 
        y las l√≠neas punteadas las mediciones actuales (post-mantenimiento).
        """)
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            show_ref = st.checkbox("Mostrar Referencia", value=True, key="show_ref_overlay")
            show_curr = st.checkbox("Mostrar Actual", value=True, key="show_curr_overlay")
        
        overlay_fig = create_validation_overlay_plot(all_validation_data, show_ref, show_curr)
        st.plotly_chart(overlay_fig, use_container_width=True)
    
    # Estad√≠sticas globales usando funci√≥n compartida
    st.markdown("#### üìà Estad√≠sticas Globales del Kit")
    st.caption(f"An√°lisis agregado de {len(all_validation_data)} est√°ndar(es)")
    
    stats_df = create_global_statistics_table(all_validation_data)
    st.dataframe(stats_df, use_container_width=True, hide_index=True)
    
    # M√©tricas destacadas
    col1, col2, col3 = st.columns(3)
    with col1:
        avg_corr = np.mean([d['validation_results']['correlation'] for d in all_validation_data])
        st.metric(
            "Correlaci√≥n Media", 
            f"{avg_corr:.6f}", 
            delta="OK" if avg_corr >= thresholds['correlation'] else "Revisar",
            delta_color="normal" if avg_corr >= thresholds['correlation'] else "inverse"
        )
    with col2:
        avg_max_diff = np.mean([d['validation_results']['max_diff'] for d in all_validation_data])
        st.metric(
            "Max Œî Media", 
            f"{avg_max_diff:.6f} AU",
            delta="OK" if avg_max_diff <= thresholds['max_diff'] else "Revisar",
            delta_color="normal" if avg_max_diff <= thresholds['max_diff'] else "inverse"
        )
    with col3:
        avg_rms = np.mean([d['validation_results']['rms'] for d in all_validation_data])
        st.metric(
            "RMS Media", 
            f"{avg_rms:.6f}",
            delta="OK" if avg_rms <= thresholds['rms'] else "Revisar",
            delta_color="normal" if avg_rms <= thresholds['rms'] else "inverse"
        )
    
    st.markdown("---")
    
    # Offset global del kit
    global_offset = np.mean([d['validation_results']['mean_diff'] for d in all_validation_data])
    
    st.metric(
        "üéØ Offset Global del Kit", 
        f"{global_offset:.6f} AU",
        help="Desplazamiento sistem√°tico promedio entre mediciones pre y post-mantenimiento"
    )
    
    if abs(global_offset) < OFFSET_LIMITS['negligible']:
        st.success("‚úÖ Offset despreciable - Excelente alineamiento")
    elif abs(global_offset) < OFFSET_LIMITS['acceptable']:
        st.info("‚ÑπÔ∏è Offset peque√±o - Alineamiento aceptable")
    else:
        st.warning(f"‚ö†Ô∏è Offset significativo detectado ({'+' if global_offset > 0 else ''}{global_offset:.6f} AU)")
    
    st.divider()
    
    # ==========================================
    # SECCI√ìN 4: AN√ÅLISIS INDIVIDUAL
    # ==========================================
    st.markdown("### 4Ô∏è‚É£ An√°lisis Detallado por Est√°ndar")
    st.info("An√°lisis individual de cada est√°ndar con gr√°ficos comparativos, diferencias espectrales y regiones cr√≠ticas.")

    # Filtro de b√∫squeda
    search_filter = st.text_input(
        "üîç Buscar est√°ndar por ID:",
        placeholder="Escribe para filtrar...",
        help="Filtra la lista de est√°ndares por ID"
    )

    # Filtrar lista seg√∫n b√∫squeda
    if search_filter:
        filtered_indices = [
            i for i in range(len(all_validation_data))
            if search_filter.lower() in str(all_validation_data[i]['id']).lower()
        ]
    else:
        filtered_indices = list(range(len(all_validation_data)))

    if len(filtered_indices) == 0:
        st.warning("‚ö†Ô∏è No se encontraron est√°ndares que coincidan con la b√∫squeda")
        return

    # Mostrar cu√°ntos resultados
    if search_filter:
        st.caption(f"Mostrando {len(filtered_indices)} de {len(all_validation_data)} est√°ndares")

    # Selector con lista filtrada
    selected_sample_filtered = st.selectbox(
        "Selecciona est√°ndar:",
        filtered_indices,
        format_func=lambda x: f"{all_validation_data[x]['id']} - {all_validation_data[x]['ref_note']}",
        key="sample_selector"
    )

    sample_data = all_validation_data[selected_sample_filtered]
    
    # Tabs de an√°lisis detallado
    tab1, tab2, tab3 = st.tabs([
        "üìà Gr√°ficos",
        "üìã Regiones Cr√≠ticas",
        "üìÑ M√©tricas"
    ])
    
    with tab1:
        sample_label = f"{sample_data['id']} (Ref: {sample_data['ref_note']} | Act: {sample_data['curr_note']})"
        # Usar funci√≥n compartida para crear gr√°fico
        fig = create_validation_plot(
            sample_data['reference'],
            sample_data['current'],
            sample_data['diff'],
            sample_label
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Usar funci√≥n compartida para analizar regiones cr√≠ticas
        regions_df = analyze_critical_regions(
            sample_data['reference'],
            sample_data['current'],
            CRITICAL_REGIONS,
            num_channels
        )
        st.dataframe(regions_df, use_container_width=True, hide_index=True)
        st.caption("* = Regi√≥n ajustada a rango del instrumento (900-1700 nm)")
    
    with tab3:
        val_res = sample_data['validation_results']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### M√©tricas Calculadas")
            metrics_data = {
                'M√©trica': ['Correlaci√≥n', 'Max Diferencia', 'RMS', 'Media Œî', 'Shift Espectral'],
                'Valor': [
                    f"{val_res['correlation']:.6f}",
                    f"{val_res['max_diff']:.6f} AU",
                    f"{val_res['rms']:.6f}",
                    f"{val_res['mean_diff']:.6f}",
                    f"{sample_data['shift_magnitude']:.1f} px" if sample_data['has_shift'] else "No detectado"
                ]
            }
            st.dataframe(pd.DataFrame(metrics_data), use_container_width=True, hide_index=True)
        
        with col2:
            st.markdown("#### Evaluaci√≥n")
            checks_data = {
                'Criterio': ['Correlaci√≥n', 'Diferencia M√°xima', 'RMS'],
                'Umbral': [
                    f"‚â• {thresholds['correlation']}",
                    f"‚â§ {thresholds['max_diff']} AU",
                    f"‚â§ {thresholds['rms']}"
                ],
                'Estado': [
                    "‚úÖ OK" if val_res['checks']['correlation'] else "‚ùå Fallo",
                    "‚úÖ OK" if val_res['checks']['max_diff'] else "‚ùå Fallo",
                    "‚úÖ OK" if val_res['checks']['rms'] else "‚ùå Fallo"
                ]
            }
            st.dataframe(pd.DataFrame(checks_data), use_container_width=True, hide_index=True)
    
    st.divider()
    
    # ==========================================
    # SECCI√ìN 5: GENERACI√ìN DE INFORME
    # ==========================================
    st.markdown("### 5Ô∏è‚É£ Generar Informe de Validaci√≥n")
    st.info("""
    Completa la informaci√≥n del servicio para generar un informe HTML profesional 
    con todos los resultados de la validaci√≥n.
    """)
    
    st.markdown("#### üìã Informaci√≥n del Servicio")
    
    col1, col2 = st.columns(2)
    
    with col1:
        sensor_serial = st.text_input(
            "N√∫mero de Serie del Sensor:",
            placeholder="Ej: NIR-2024-001",
            help="N√∫mero de serie √∫nico del equipo NIR"
        )
        
        customer_name = st.text_input(
            "Cliente:",
            placeholder="Ej: Universidad de Barcelona",
            help="Nombre del cliente o instituci√≥n"
        )
    
    with col2:
        technician_name = st.text_input(
            "T√©cnico Responsable:",
            placeholder="Ej: Juan P√©rez",
            help="Nombre del t√©cnico que realiz√≥ el servicio de mantenimiento"
        )
        
        service_notes = st.text_area(
            "Notas del Servicio:",
            placeholder="Ej: Cambio de l√°mpara hal√≥gena, ajuste √≥ptico, limpieza de ventana...",
            help="Observaciones relevantes del mantenimiento realizado",
            height=100
        )
    
    st.markdown("---")
    
    # Bot√≥n de generaci√≥n centrado
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button("üì• Generar Informe HTML", type="primary", use_container_width=True):
            if not sensor_serial or not customer_name or not technician_name:
                st.error("‚ùå Por favor completa los campos obligatorios: N√∫mero de Serie, Cliente y T√©cnico")
            else:
                with st.spinner("‚è≥ Generando informe completo..."):
                    try:
                        from core.validation_kit_report_generator import generate_validation_report
                        
                        # Preparar datos para el reporte
                        report_data = {
                            'sensor_serial': sensor_serial,
                            'customer_name': customer_name,
                            'technician_name': technician_name,
                            'service_notes': service_notes,
                            'validation_data': all_validation_data,
                            'results_df': results_df,
                            'thresholds': thresholds,
                            'n_ok': n_ok,
                            'n_warn': n_warn,
                            'n_fail': n_fail,
                            'num_channels': num_channels,
                            'ref_filename': ref_file.name,
                            'curr_filename': curr_file.name
                        }
                        
                        html_content = generate_validation_report(report_data)
                        
                        # Descargar
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        filename = f"STANDARDS_VALIDATION_Report_{sensor_serial.replace(' ', '_')}_{timestamp}.html"
                        
                        st.success("‚úÖ Informe generado correctamente")
                        
                        st.download_button(
                            label="üíæ Descargar Informe HTML",
                            data=html_content,
                            file_name=filename,
                            mime="text/html",
                            use_container_width=True
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå Error al generar informe: {str(e)}")
                        with st.expander("üîç Ver detalles del error"):
                            import traceback
                            st.code(traceback.format_exc())


if __name__ == "__main__":
    main()